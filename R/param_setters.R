#' Setting the parameters for TFCE correction 
#'
#' \code{tfceParams} sets the parameters for TFCE correction
#' @param ChN channel neighbourhood matrix
#' @param EH numeric vector giving the E and H parameters
#' @param steps integer value indicating the number of thresholding steps 
#' (default: 50L)
#' @param auto logical; if set to TRUE (default), ChN and EH are set 
#' automagically. See Details.
#' @details The TFCE correction has three parameters: the channel neighbourhood
#' matrix, and the E and H parameters. The channel neighb. matrix is usually 
#' generated by \code{\link{chanNb}}. The E and H parameters should be fixed at 
#' c(0.66, 2) for t-tests and c(0.66, 1) for F-tests, unless you have very
#' good reasons to change these defaults. 
#' If 'auto' is TRUE and 'ChN' is NULL, \code{tfceParams} looks for an object 
#' named '.arraydat' and tries to extract its 'ChN' attribute. This usually 
#' works because in the functions which perform TFCE correction 
#' (\code{\link{arrayAnova}} and \code{\link{arrayTtest}}), the data argument is
#' named as \code{.arraydat}. If this automatic lookup fails, \code{tfceParams}
#' fails with an informative error message. 
#' If 'auto' is TRUE and 'EH' is NULL, \code{tfceParams} investigates if it was 
#' called from a function which has "anova" in its name (upper- or lower-case 
#' does not matter) or not. In the former case EH is set to \code{c(0.66, 1)}, 
#' otherwise \code{c(0.66, 2)}.
#' @note IMPORTANT! Be extremely careful with the 'auto' parameter. 
#' @export
#' @examples
#' # use example dataset
#' data(erps)
#' 
#' # create channel neighb. matrix
#' chan_pos <- attr(erps, "chan")
#' chn <- chanNb(chan_pos, alpha = 0.7) # see ?chanNb how to find alpha
#' attr(erps, "ChN") <- chn
#' 
#' # create a dummy function
#' myAnova <- function(.arraydat) {
#'     tfce <- tfceParams()
#'     tfce
#' }
#' 
#' # check what it returns
#' res <- myAnova(erps)
#' str(res)
#' stopifnot(identical(res, 
#'                     structure(list(ChN = chn, EH = c(0.66, 1), steps = 50L), 
#'                               class = "tfceParams")
#'                    ))
#' 
#' # if called from the global environment, provide ChN and EH
#' myAnova2 <- function(.arraydat, tfce = NULL) tfce
#' 
#' # this fails
#' res <- try(myAnova2(erps, tfce = tfceParams()), silent = TRUE)
#' stopifnot(inherits(res, "try-error"))
#' res[1]
#' 
#' # this works
#' res <- myAnova2(erps, tfce = tfceParams(ChN = chn, EH = c(0.66, 1)))
#' str(res)
#' 
tfceParams <- function(ChN = NULL, EH = NULL, auto = TRUE, steps = 50L) {
    if (any(c(is.null(ChN), is.null(EH)))) {
        if (!auto) {
            stop("If 'auto' is FALSE, both 'ChN' and 'EH' must be explicitly given")    
        }
        if (auto && identical(parent.frame(), globalenv())) {
            stop("Both ChN and EH must be explicitly provided if this function is called from the global environment")
        }
    }
    if (auto & is.null(ChN)) {
        ChN <- try(attr(get(".arraydat", 
                            envir = parent.frame(), mode = "numeric"), 
                        "ChN"), 
                   silent = TRUE)
        if (inherits(ChN, "try-error")) {
            stop("Automatic extraction of the channel neigbourhood matrix failed. Provide 'ChN' parameter explicitly.")
        }
    }
    if (auto & is.null(EH)) {
        fn <- tolower(deparse(sys.call(-1)[[1]]))
        EH <- 
            if (grepl("anova", fn)) {
                c(0.66, 1)
            } else {
                c(0.66, 2)
            }
    }
    # checks
    assertMatrix(ChN, any.missing = FALSE)
    assertIntegerish(ChN)
    assertNumeric(EH, any.missing = FALSE, len = 2L)
    assertIntegerish(steps, any.missing = FALSE, len = 1L)
    # return
    structure(list(ChN = ChN, EH = EH, steps = as.integer(steps)), 
              class = "tfceParams")
}

#' Setting the parameters for parallel computation
#' 
#' \code{parallelParams} sets the parameters for parallel computation and 
#' registers the cluster. Newly registered clusters should be stopped after
#' the computations are performed.
#' @param cl an object of class "cluster" (default: NULL)
#' @param method character string of the chosen parallelization method; if 
#' 'auto' (default), 'snow' is chosen on Windows and 'multicore' otherwise
#' @param ncores integer; the number of cores 
#' @param ... options to be passed to the function spawning the workers. See 
#' 'Details' in \code{\link[parallel]{makeCluster}} and 
#' \code{\link[parallel]{mclapply}} for snow- and multicore-parallelization,
#' respectively (for multicore, one can use the "preschedule", "set.seed", 
#' "silent" options, e.g. \code{options = list(preschedule = FALSE)}.
#' @export
#' @return \code{parallelParams} returns a list with five elements:
#' \itemize{
#' \item{cl: }{the cluster if a snow-type cluster was requested}
#' \item{cl_new: }{a logical whether the cluster was created by 
#' \code{parallelParams}}
#' \item{snow_options: }{a list of options for snow-clusters}
#' \item{mc_options: }{a list of options for multicore-clusters}
#' }
#' @note If \code{cl_new = TRUE}, you should stop the cluster after the 
#' computations (see Examples).
#' @examples
#' # create a function  which computes the range of values in each column of
#' # a matrix and can run in single-core or parallel mode
#' rangeColumns <- function(x, parallel = FALSE) {
#'     # 
#'     stopifnot(require(doParallel))
#'     #
#'     # parallel argument can be a logical or a direct call to parallelParams
#'     # or a .(key = value)-type call
#'     parallel <- argumentDeparser(substitute(parallel), "parallelParams", 
#'                                  null_params = list(ncores = 0L))
#'     #
#'     # stop cluster on exit if it was created by parallelParams
#'     ob <- getDoBackend()
#'     if (is.logical(parallel) && !parallel) {
#'         registerDoSEQ()
#'     } else if (inherits(parallel, "parallelParams") && parallel$cl_new) {
#'         on.exit(stopCluster(parallel$cl))
#'     }
#'     on.exit(setDoBackend(ob), add = TRUE)
#'     #
#'     # call foreach and compute range
#'     out <- foreach(xi = iter(x, by = "col"), .combine = "cbind",
#'                    .options.snow = parallel$snow_options,
#'                    .options.multicore = parallel$mc_options) %dopar% 
#'                    range(xi)
#'     #
#'     # return with sensible dimension names
#'     dimnames(out) <- list(range = c("min", "max"), colnames(x))
#'     out
#' }
#'     
#' # create a toy data matrix
#' mat <- matrix(rnorm(100), 25, 4)
#' colnames(mat) <- paste0("column", 1:4)
#' 
#' # compute the range of values in each column and print to the console
#' ranges_parallel <- rangeColumns(mat, 
#'                                 parallel = .(method = "snow", ncores = 2L))
#' ranges_parallel
#' 
#' # compare to single-core calculation
#' ranges_single <- apply(mat, 2, range)
#' stopifnot(identical(unname(ranges_parallel), 
#'                     unname(ranges_single)))
#' 
parallelParams <- function(cl = NULL, method = c("auto", "snow", "multicore"),
                           ncores = parallel::detectCores()-1, ...) {
    method <- match.arg(method)
    opts <- list(...)
    if (length(opts) == 0L) opts <- NULL
    mc_options <- snow_options <- NULL
    cl_new <- FALSE
    if (is.null(cl)) {
        if (ncores <= 1L) {
            registerDoSEQ()
        } else if (.Platform$OS.type == "windows" || method == "snow") {
            snow_options <- opts
            cl <- makePSOCKcluster(as.integer(ncores))
            cl_new <- TRUE
            registerDoParallel(cl = cl)
        } else {
            mc_options <- opts
            registerDoParallel(cores = as.integer(ncores))
        }
    } else {
        snow_options <- opts
        registerDoParallel(cl = cl)
    }
    # return
    list(cl = cl, cl_new = cl_new, 
         snow_options = snow_options, mc_options = mc_options)
}
